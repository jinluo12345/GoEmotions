# GoEmotions Emotion Classification Project

æœ¬é¡¹ç›®åŸºäº **Qwen2.5-7B-Instruct** æ¨¡å‹ï¼Œé’ˆå¯¹ **GoEmotions** æ•°æ®é›†è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡çš„å¾®è°ƒã€‚é¡¹ç›®åŒ…å« **SFT (Supervised Fine-Tuning)** å’Œ **GRPO (Group Relative Policy Optimization)** ä¸¤ç§è®­ç»ƒé˜¶æ®µï¼Œæ”¯æŒ Chain-of-Thought (CoT) æ¨ç†ä»¥åŠ Token çº§åˆ«çš„æ³¨æ„åŠ›æœºåˆ¶åˆ†æã€‚

## ğŸ“ ç›®å½•ç»“æ„

å»ºè®®çš„é¡¹ç›®æ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š`markdown
# GoEmotions Emotion Classification Project

æœ¬é¡¹ç›®åŸºäº **Qwen2.5-7B-Instruct** æ¨¡å‹ï¼Œé’ˆå¯¹ **GoEmotions** æ•°æ®é›†è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡çš„å¾®è°ƒã€‚é¡¹ç›®åŒ…å« **SFT (Supervised Fine-Tuning)** å’Œ **GRPO (Group Relative Policy Optimization)** ä¸¤ç§è®­ç»ƒé˜¶æ®µï¼Œæ”¯æŒ Chain-of-Thought (CoT) æ¨ç†ä»¥åŠ Token çº§åˆ«çš„æ³¨æ„åŠ›æœºåˆ¶åˆ†æã€‚

## ğŸ› ï¸ ç¯å¢ƒä¾èµ–

è¯·ç¡®ä¿å®‰è£…äº†ä»¥ä¸‹æ ¸å¿ƒåº“ï¼š

```bash
pip install torch pandas numpy datasets transformers peft trl accelerate scikit-learn vllm
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æ¨¡å‹ä¸‹è½½

ä½¿ç”¨ `download.`download.py` ä¸‹è½½ Qwen2.5 åŸºç¡€æ¨¡å‹ï¼š

```bash
python download.py
```

*æ³¨æ„ï¼šè¯·*æ³¨æ„ï¼šè¯·åœ¨è„šæœ¬ä¸­ä¿®æ”¹ `target_dir` ä¸ºä½ çš„å®é™…è·¯å¾„ã€‚*

### 2. SFT è®­ç»ƒ (Supervised Fine-Tuning)

ä½¿ç”¨ `main_SFT.py` è¿›è¡Œç›‘ç£å¾®è°ƒã€‚è¯¥è„šæœ¬ä½¿ç”¨ `trl` åº“çš„ `SFTTrainer` å’Œ LoRA æŠ€æœ¯ã€‚

```bash
python main_SFT.py \
    --model_path "/path/to/Qwen2.5-7B-Instruct" \
    --train_data_path "/path/to/data/group/train.tsv" \
    --label_path "/path/to/data/group/labels.txt" \
    --test_data_path "/path/to/data/group/test_small.tsv"
```

### 3. GRPO è®­ç»ƒ (Reinforcement Learning)

GRPO (Group Relative Policy Optimization) ç”¨äºè¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹ï¼Œé¼“åŠ±æ¨¡å‹ç”Ÿæˆå‡†ç¡®çš„æ ‡ç­¾æ ¼å¼å¹¶è¿›è¡Œæ¨ç†ã€‚

**å¯åŠ¨æ–¹å¼ï¼š**
ä½¿ç”¨ `scripts/` æ–‡ä»¶å¤¹ä¸‹çš„ Shell è„šæœ¬è¿›è¡Œå¤š GPU åˆ†å¸ƒå¼è®­ç»ƒï¼š

```bash
bash scripts/main_grpo_original_Qwen2_5-7b.sh
```

**GRPO å¥–åŠ±å‡½æ•°è¯´æ˜ï¼š**

* **Accuracy**Accuracy Reward:** é¢„æµ‹æ ‡ç­¾ä¸çœŸå®æ ‡ç­¾çš„ Jaccard ç›¸ä¼¼ç³»æ•°ï¼ˆäº¤å¹¶æ¯”ï¼‰ã€‚å…¬å¼ä¸ºï¼š
  [ R_{acc} = \frac{|P \cap G|}{|P \cup G|} ]
  å…¶ä¸­ ( P ) ä¸ºé¢„æµ‹æ ‡ç­¾é›†åˆï¼Œ( G ) ä¸ºçœŸå®æ ‡ç­¾é›†åˆã€‚
* **Length Reward:** æƒ©ç½šè¿‡é•¿çš„å›å¤ï¼Œé˜²æ­¢æ¨¡å‹è¾“å‡ºå†—ä½™ä¿¡æ¯ã€‚

### 4. æ¨¡å‹åˆå¹¶

è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨ `merge_`merge_lora.py` å°† LoRA æƒé‡åˆå¹¶å›åŸºç¡€æ¨¡å‹ï¼Œä»¥ä¾¿è¿›è¡Œæ¨ç†æˆ–éƒ¨ç½²ã€‚

```bash
python merge_lora.py
```

*è¯·åœ¨è„šæœ¬å†…çš„ `if **name** == "**main**":*è¯·åœ¨è„šæœ¬å†…çš„ `if __name__ == "__main__":` éƒ¨åˆ†ä¿®æ”¹ `base_model_path` å’Œ `training_output_dir`ã€‚*

---

## âš¡ æ¨ç†ä¸è¯„ä¼° (Inference)

ä½¿ç”¨ `inference.py` å¯¹æµ‹è¯•é›†è¿›è¡Œè¯„ä¼°ã€‚æ”¯æŒå¤šç§åç«¯ (`vllm`, `hf`, `bert`) å’Œæ€ç»´é“¾ (CoT) æ¨¡å¼ã€‚

### å‚æ•°è¯´æ˜

* `--backend`: æ¨ç†åç«¯ï¼Œæ¨èä½¿ç”¨ `vllm` ä»¥è·å¾—æ›´å¿«çš„é€Ÿåº¦ã€‚
